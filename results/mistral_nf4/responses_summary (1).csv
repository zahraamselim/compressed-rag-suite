id,question,ground_truth,rag_answer,no_rag_answer,chunks,avg_score,rag_words,no_rag_words,retrieval_ms,rag_gen_ms,no_rag_gen_ms
1,What is the main focus of this survey paper?,This paper presents a comprehensive survey of model compression techniques for Large Language Models...,The main focus of this survey paper is to provide insights into the current landscape of LLM compres...,"Without a specific survey paper in mind, I am unable to provide an answer to that question.",3,0.6415100807187759,26,17,31.946909999987838,5948.280029999751,3589.8718540001937
2,What challenges do Large Language Models face?,LLMs face challenges stemming from their extensive size and computational requirements. For instance...,,Large language models (LLMs) are a type of artificial intelligence that can generate human-like text...,3,0.8353432095659379,0,71,29.36643599969102,6499.0143350000835,10265.444006000052
3,What is model compression and why is it important?,"Model compression involves transforming a large, resource-intensive model into a compact version sui...",Model compression refers to the process of reducing the size of large language models (LLMs) while m...,Model compression refers to the process of reducing the size of a trained machine learning model wit...,3,0.8734372140087743,49,86,26.76197900018451,7491.8795180001325,10402.281692000088
4,What are the main categories of model compression techniques covered in this survey?,"The survey covers four main categories: (1) Quantization, (2) Pruning, (3) Knowledge Distillation, a...",,The main categories of model compression techniques covered in this survey include: 1. Pruning and q...,3,0.898375500430778,0,74,33.227893999992375,4940.674855999987,10287.21838599995
5,What metrics are used to evaluate compressed LLMs?,"Key metrics include: Model Size (number of parameters), FLOPs (floating-point operations), MFU (Mean...",,Compressed language models (LLMs) are typically evaluated using a combination of quantitative and qu...,3,0.8606086121098802,0,43,27.09214400010751,12808.965234000425,10298.795647000134
6,What is the difference between FLOPs and MFU?,FLOPs measures the theoretical computational efficiency (number of floating-point operations require...,FLOPs and MFU are both metrics used to evaluate the efficiency and performance of machine learning m...,FLOPs (floating-point operations per second) and MFU (most frequently used) are two different concep...,3,0.6760161045193295,74,65,26.147595000111323,11774.263563000204,10275.832333999915
7,What is quantization in the context of LLMs?,"Quantization refers to the process of reducing the number of bits (i.e., precision) in the parameter...","In the context of LLMs, quantization refers to the process of reducing the precision of model parame...","Quantization refers to the process of reducing the precision or accuracy of a model's parameters, we...",3,0.8512720921970711,61,61,28.14168700024311,9973.981467000158,10320.429646999855
8,What is the difference between QAT and PTQ?,The primary distinction lies in whether retraining is needed during quantization. Post-Training Quan...,,"QAT stands for Quality Assurance Testing, which is a process of testing software or systems to ensur...",3,0.6875701087998861,0,66,26.548792000085086,8236.294974999964,10178.997246000108
9,What are the three categories of Post-Training Quantization?,PTQ for LLMs is categorized into three groups: (1) Weight-Only Quantization - focuses solely on quan...,The three categories of Post-Training Quantization are: 1. PTQ: This approach enables direct use of ...,Post-training quantization refers to techniques used to reduce the precision of model weights and ac...,3,0.7957004113376106,33,63,27.82257499984553,7153.152422999938,10345.106327999929
10,What is GPTQ and how does it work?,GPTQ is a layer-wise quantization method based on Optimal Brain Quantization (OBQ) that updates weig...,GPTQ stands for Gradient-based Pruning and Quantization. It is a layer-wise quantization method base...,"GPTQ stands for ""Generative Pre-Training of Quantum Circuits."" It is a quantum computing technique t...",3,0.7264488477579647,19,85,28.054729999894334,5253.480515999854,10247.914255000069
11,What is AWQ's approach to weight quantization?,AWQ (Activation-aware Weight Quantization) stores the top 1% of weights that have the most significa...,,"AWS Quantum (AWSQ) uses a technique called ""weight quantization"" to reduce the precision of model we...",3,0.8700377680182824,0,72,28.77705499986405,8340.599395000027,10346.093057999951
12,Why do LLMs have issues with activation quantization?,"LLMs have outliers in activations, and the performance declines significantly if these activations w...",LLMs have issues with activation quantization because it can lead to a decrease in accuracy during i...,Activation quantization is a technique used to reduce the precision of activations in neural network...,3,0.8708407632855657,40,68,28.501022000000376,6408.788943000218,10333.383842999865
13,What is SmoothQuant's approach?,SmoothQuant designs a per-channel scaling transformation to smooth the activation outliers based on ...,"SmoothQuant uses a combination of methods such as layer normalization, linear layer weights, and qua...",SmoothQuant is a quantitative finance platform that uses machine learning algorithms to analyze fina...,3,0.6028492077229034,27,80,26.381655000022874,13732.39142500006,10248.562719000347
14,What is KV cache quantization and why is it important?,"KV cache quantization targets the KV cache, which stores keys and values of attention layers. It's i...",KV cache quantization is a technique used to reduce the memory footprint of large language models (L...,Key-Value (KV) cache quantization refers to the process of reducing the precision or accuracy of val...,3,0.8364306615053358,59,76,27.23667899999782,20201.51096299969,10263.924202999988
15,What is pruning in neural networks?,Pruning is a powerful technique to reduce the size or complexity of a model by removing redundant co...,Pruning in neural networks refers to the process of removing unnecessary or redundant connections fr...,Pruning in neural networks refers to the process of removing unnecessary or redundant connections be...,3,0.8764424085163723,70,78,26.596357000016724,10711.95291999993,10340.351217000261
16,What are the three types of pruning methods?,The three types are: (1) Unstructured Pruning - prunes individual parameters resulting in irregular ...,Magnitude-based Pruning 2. Regularization-based Pruning 3.,Pruning is a technique used to improve the accuracy and performance of machine learning models by re...,3,0.8293721327649072,6,82,28.286217999720975,13260.484812999948,10225.47423900005
17,What is SparseGPT?,SparseGPT is a one-shot pruning strategy without retraining that frames pruning as an extensive spar...,SparseGPT is an innovative approach in the domain of unstructured pruning of LLMs that introduces a ...,SparseGPT is a variant of the popular language model called GPT (Generative Pre-Trained Transformer)...,3,0.8219295003715263,39,77,26.183966999724362,19029.068039999856,10310.246141999869
18,What is Wanda's pruning approach?,Wanda achieves model sparsity by pruning weights with the smallest magnitudes multiplied by the norm...,,"Wanda, a large language model trained by Mistral AI, uses a technique called ""pruning"" to reduce the...",3,0.8266254676775334,0,88,27.589520999754313,8568.425958999796,10391.838188000293
19,What are the three categories of structured pruning metrics?,Structured pruning works are divided into: (1) Loss-based Pruning - assesses significance by measuri...,Structured fluctuation metric - used by FLAP to assess and identify columns in the weight matrix sui...,Structured pruning metrics can be categorized into three main groups: 1. **Pruning Efficiency**: Thi...,3,0.8444777721853587,92,81,28.2566340001722,21282.020968000325,10359.245133000059
20,What is N:M sparsity?,N:M sparsity is a semi-structured pruning pattern where every M contiguous elements leave N non-zero...,N:M sparsity refers to a technique used in neural network pruning where the weight matrix is divided...,"In the context of matrices, ""N:M sparsity"" refers to a type of sparse matrix representation where ea...",3,0.7817364308621997,44,74,26.486814999771013,7263.6238109998885,10268.200451000212
