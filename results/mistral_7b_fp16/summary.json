{
  "latency_ms_per_token": 63.62993283440506,
  "throughput_tokens_per_sec": 15.664722005347258,
  "peak_memory_gb": 6.848927021026611,
  "model_size_gb": 13.48877739906311,
  "perplexity": 13.313827352511062,
  "total_eval_time_seconds": 195.29006814956665
}